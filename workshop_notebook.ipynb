{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning-based shape correspondence workshop (June 2024)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# Overview\n",
    "The steps in this notebook are as follows:\n",
    "\n",
    "0. Install prerequisites and set up\n",
    "1. Load data\n",
    "2. Define some preprocessing ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use Colab \n",
    "Colab is a free ML playground from google. It allows you free access to limited resources, including a GPU and some storage space. Even though the limits are quite small: ~50GB disk, 12GB RAM & a T4 GPU, you can do some pretty cool stuff with it. \n",
    "\n",
    "__You will need a Google account to sign into it.__\n",
    "\n",
    "*Important*:\n",
    "\n",
    "We are going to be training a Convolutional Neural Network (CNN), so we need to get a GPU. To do this, click \"Runtime\" in the menu across the top of the colab page, then select \"Change Runtime Type\". From the dropdown, select GPU and click Save. The runtime will then reboot and you should have a GPU. To find out what you got, run the cell below this text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find out what GPU we got (and make sure we actually have one!)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download all the data and network library! This may take a little while...\n",
    "\n",
    "## Processed data\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    !wget -O /content/data_directory.tar.gz https://www.dropbox.com/scl/fi/hgjapycrcuste048yh6b9/data_directory.tar.gz?rlkey=c3eerq4g2xnf7faw8olkjhmp6&st=bpgzfl0l&dl=0 \n",
    "    !tar -xzf /content/data_directory.tar.gz -C /content/\n",
    "    !rm /content/data_directory.tar.gz\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    !wget -O ./data_directory.tar.gz https://www.dropbox.com/scl/fi/hgjapycrcuste048yh6b9/data_directory.tar.gz?rlkey=c3eerq4g2xnf7faw8olkjhmp6&st=khq2k6i9&dl=0\n",
    "    !tar -xzf ./data_directory.tar.gz -C ./\n",
    "    !rm ./data_directory.tar.gz\n",
    "\n",
    "# network library files and images\n",
    "!git clone https://github.com/edhendo/test_workshop.git\n",
    "!cp -r test_workshop/neuromorph_adapted/ .\n",
    "!cp -r test_workshop/images/ .\n",
    "!rm -r test_workshop/\n",
    "\n",
    "# pretrained model weights\n",
    "if IN_COLAB:\n",
    "    !wget -O /content/ckpt_ep229.pth https://www.dropbox.com/scl/fi/bj2564h5oyyu0c4d9v0l6/ckpt_ep229.pth?rlkey=sktsapnqmn5h8w5ngwur9v0r8&st=ed9apxpf&dl=0\n",
    "else:\n",
    "    !wget -O ./ckpt_ep229.pth https://www.dropbox.com/scl/fi/bj2564h5oyyu0c4d9v0l6/ckpt_ep229.pth?rlkey=sktsapnqmn5h8w5ngwur9v0r8&st=ed9apxpf&dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install open3d\n",
    "!pip install pyvista==0.37.0\n",
    "!apt install libgl1-mesa-glx xvfb\n",
    "!pip install trame-vtk\n",
    "!pip install ipywidgets\n",
    "!pip install pygeodesic\n",
    "!pip install torch_geometric\n",
    "!pip install torch_scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by exploring the dataset, visualising the meshes, describing the data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "import pyvista\n",
    "pyvista.start_xvfb()\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "def pyvistarise(verts, triangles):\n",
    "    return pyvista.PolyData(verts, np.insert(triangles, 0, 3, axis=1), deep=True, n_faces=len(triangles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = o3d.io.read_triangle_mesh(\"data/meshes/camel.obj\")\n",
    "vertices = np.asarray(mesh.vertices)\n",
    "vertices = vertices[:, [0,2,1]]\n",
    "mesh.vertices = o3d.utility.Vector3dVector(vertices)\n",
    "o3d.visualization.draw_plotly([mesh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verts = np.asarray(mesh.vertices)\n",
    "triangles = np.asarray(mesh.triangles)\n",
    "pyv_mesh = pyvistarise(verts, triangles)\n",
    "pyvista.global_theme.background = 'white'\n",
    "plotter = pyvista.Plotter(notebook=True)\n",
    "plotter.add_mesh(pyv_mesh)\n",
    "plotter.show(jupyter_backend=\"static\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduce supervised and unsupervised learning, why unsupervised learning is most popular in this case. We need some metric to drive the learning process - encourage the model to make reasonable correspondence predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talk about geodesic paths and distance - how these can be used in the learning process\n",
    "\n",
    "![image of s](https://drive.google.com/file/d/1HqZwV4U1SkGGDeRfbjd8cp6fOKVX22Us/view?usp=drive_link)\n",
    "\n",
    "Then introduce registration loss, chamfer matching - overlap of the shapes\n",
    "\n",
    "Its possible to attain perfect registration by deforming a shape wildly (present example) - need a way of regularising the allowed deformations - distortion metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing:\n",
    "\n",
    "Start by computing the geodesic matrices for each shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygeodesic.geodesic as geodesic\n",
    "from neuromorph_adapted.utils.utils import getFiles\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_folder = \"data/meshes\"\n",
    "output_folder = \"data/geodesic_distances\"\n",
    "\n",
    "fnames = getFiles(data_folder)\n",
    "\n",
    "def compute_geodesic_distances(vertices, triangles):\n",
    "    # compute geodesic distances between all pairs of vertices\n",
    "    n_vertices = vertices.shape[0]\n",
    "    geo_alg = geodesic.PyGeodesicAlgorithmExact(vertices, triangles)\n",
    "    D = np.zeros((n_vertices, n_vertices), dtype=np.float16)\n",
    "    for source_index in tqdm(range(n_vertices)):\n",
    "        D[source_index], _ = geo_alg.geodesicDistances(np.array([source_index]))\n",
    "    try:\n",
    "        assert (D - D.T < 1e-4).all()\n",
    "    except AssertionError:\n",
    "        print(f\"Assertion error - max value: {np.abs(D - D.T).max()}\")\n",
    "        # If nan -> It's likely the mesh is not a single connected component -> run some connected component analysis\n",
    "        return None\n",
    "    return D\n",
    "\n",
    "fname = fnames[0]\n",
    "mesh = o3d.io.read_triangle_mesh(join(data_folder, fname))\n",
    "vertices = np.asarray(mesh.vertices)\n",
    "triangles = np.asarray(mesh.triangles)\n",
    "D = compute_geodesic_distances(vertices, triangles)\n",
    "if D is not None:\n",
    "    print(f\"Computed geodesic distances for {fname}\")\n",
    "    np.save(join(output_folder, fname.replace(\".obj\", \".npy\")), D)\n",
    "else:\n",
    "    print(f\"Failed to compute geodesic distances for {fname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT!\n",
    "Need to restart the virtual frame buffer after KeyboardInterrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyvista.start_xvfb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating full matrices takes too long! So calculate ahead of time and share.\n",
    "\n",
    "data/geodesic_distances are matrices we need\n",
    "\n",
    "As an example get the students to calculate the geodesic distance from a single point and visualise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# short example plotting a geodesic matrix\n",
    "import matplotlib.pyplot as plt\n",
    "if False:\n",
    "    camel_geodesic_distances = np.load(\"data/geodesic_distances/camel.npy\")\n",
    "    plt.imshow(camel_geodesic_distances, cmap=\"magma\")\n",
    "    plt.title(\"Geodesic distances\")\n",
    "    plt.xlabel(\"Index i\")\n",
    "    plt.ylabel(\"Index j\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygeodesic.geodesic as geodesic\n",
    "from os.path import join\n",
    "data_folder = \"data/meshes\"\n",
    "\n",
    "fname = \"camel.obj\"\n",
    "mesh = o3d.io.read_triangle_mesh(join(data_folder, fname))\n",
    "vertices = np.asarray(mesh.vertices)[:, [0,2,1]] # just reordering x, y, z for visualisation\n",
    "triangles = np.asarray(mesh.triangles)\n",
    "geo_alg = geodesic.PyGeodesicAlgorithmExact(vertices, triangles)\n",
    "source_index = 4000\n",
    "target_index = 1500\n",
    "distances, _ = geo_alg.geodesicDistances(np.array([source_index]))\n",
    "distance, path = geo_alg.geodesicDistance(source_index, target_index)\n",
    "\n",
    "pyv_mesh = pyvistarise(vertices, triangles)\n",
    "pyvista.global_theme.background = 'white'\n",
    "plotter = pyvista.Plotter(notebook=True)\n",
    "\n",
    "sargs = dict(title_font_size=28, label_font_size=26, shadow=False, n_labels=5, italic=False, fmt=\"%.1f\", font_family=\"arial\", color='black', bold=False, title=\"Geodesic distance\")\n",
    "plotter.add_mesh(pyv_mesh, show_edges=False, scalars=distances, cmap=\"YlOrRd\", scalar_bar_args=sargs)\n",
    "plotter.add_lines(path, color='b', width=5)\n",
    "plotter.show(jupyter_backend=\"static\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to include some description of the network architecture, what each bit does, how it works and some figures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try inferencing a randomly initialised network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "from neuromorph_adapted.model.interpolation_net import *\n",
    "from neuromorph_adapted.utils.arap import ArapInterpolationEnergy\n",
    "from neuromorph_adapted.data.data import *\n",
    "from neuromorph_adapted.utils.utils import ParametersBase\n",
    "import pyvista\n",
    "import pickle\n",
    "\n",
    "# load the model and some mesh data\n",
    "data_folder = \"data/meshes\"\n",
    "source_mesh = o3d.io.read_triangle_mesh(join(data_folder, \"bison.obj\"))\n",
    "target_mesh = o3d.io.read_triangle_mesh(join(data_folder, \"cow.obj\"))\n",
    "\n",
    "# inference\n",
    "\n",
    "class NetworkParameters(ParametersBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.num_timesteps = 0\n",
    "        self.hidden_dim = 64\n",
    "\n",
    "def run_correpondence_inference(model, source_mesh, target_mesh):\n",
    "    \n",
    "    def convert_to_batch(mesh):\n",
    "        verts = torch.tensor(np.asarray(mesh.vertices).astype(np.float32))\n",
    "        shift = torch.mean(verts, dim=0)\n",
    "        verts = verts - shift\n",
    "        #verts = verts / torch.max(torch.abs(verts))\n",
    "        triangles = torch.tensor(np.asarray(mesh.triangles))\n",
    "        return {\"verts\": verts, \"triangles\": triangles, \"shift\": shift}\n",
    "    source_data = convert_to_batch(source_mesh)\n",
    "    target_data = convert_to_batch(target_mesh)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        source_shape = batch_to_shape(source_data)\n",
    "        target_shape = batch_to_shape(target_data)\n",
    "\n",
    "        point_pred = model.get_pred(source_shape, target_shape)\n",
    "        point_pred = point_pred.cpu().numpy()\n",
    "\n",
    "        corr_out = model.match(source_shape, target_shape)\n",
    "        assignment = corr_out.argmax(dim=1).cpu().numpy()\n",
    "        assignmentinv = corr_out.argmax(dim=0).cpu().numpy()\n",
    "\n",
    "        source_verts = source_shape.verts.cpu().numpy()\n",
    "        target_verts = target_shape.verts.cpu().numpy()\n",
    "        triangles_x = source_shape.triangles.cpu().numpy()\n",
    "        triangles_y = target_shape.triangles.cpu().numpy()\n",
    "\n",
    "        result = {}\n",
    "        result[\"assignment\"] = assignment\n",
    "        result[\"assignmentinv\"] = assignmentinv\n",
    "        result[\"X\"] = {\"verts\": source_verts, \"triangles\": triangles_x, \"shift\": source_data[\"shift\"]}\n",
    "        result[\"Y\"] = {\"verts\": target_verts, \"triangles\": triangles_y, \"shift\": target_data[\"shift\"]}\n",
    "        result[\"interpolation_verts\"] = point_pred\n",
    "        result[\"raw_correspondence_predictions\"] = corr_out.cpu().numpy()\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "interpolation_energy = ArapInterpolationEnergy()\n",
    "correspondence_model = InterpolationModGeoEC(interpolation_energy, NetworkParameters()).to(device)\n",
    "\n",
    "result = run_correpondence_inference(correspondence_model, source_mesh, target_mesh)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(\"results/random_init_correspondence_result.pkl\", \"wb\") as f:\n",
    "    pickle.dump(result, f)\n",
    "\n",
    "# display outputs (visualise)\n",
    "source_verts = result[\"X\"][\"verts\"][:, [0,2,1]] # just reordering x, y, z for visualisation\n",
    "target_verts = result[\"Y\"][\"verts\"][:, [0,2,1]] # just reordering x, y, z for visualisation\n",
    "triangles_x = result[\"X\"][\"triangles\"]\n",
    "triangles_y = result[\"Y\"][\"triangles\"]\n",
    "\n",
    "# offset\n",
    "target_verts = target_verts + np.array([1,0,0])\n",
    "\n",
    "pyvista.global_theme.background = 'white'\n",
    "plotter = pyvista.Plotter(notebook=True)\n",
    "\n",
    "# Forward assignment\n",
    "# set colours on target mesh corresponding with xyz position\n",
    "target_colours = target_verts - np.min(target_verts, axis=0)\n",
    "target_colours = target_colours / np.max(target_colours, axis=0)\n",
    "target_colours = np.concatenate([target_colours, np.ones((len(target_colours), 1))], axis=1)\n",
    "# set colours on source mesh according to the predicted correspondence assignment\n",
    "assignment = result[\"assignment\"]\n",
    "source_colours = target_colours[assignment]\n",
    "\n",
    "# add points\n",
    "plotter.add_points(target_verts, opacity=1., point_size=10, render_points_as_spheres=True, scalars=target_colours, rgb=True)\n",
    "plotter.add_points(source_verts, opacity=1., point_size=10, render_points_as_spheres=True, scalars=source_colours, rgb=True)\n",
    "plotter.show(jupyter_backend=\"static\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try training the network on a small subset of data for a few epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training code\n",
    "from neuromorph_adapted.model.interpolation_net import *\n",
    "from neuromorph_adapted.utils.arap import ArapInterpolationEnergy\n",
    "from neuromorph_adapted.data.data import *\n",
    "from neuromorph_adapted.utils.utils import ParametersBase, k_fold_split_train_val_test, getFiles\n",
    "\n",
    "class NetworkParameters(ParametersBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lr = 1e-4\n",
    "        self.num_it = 1\n",
    "        self.batch_size = 16\n",
    "        self.num_timesteps = 0\n",
    "        self.hidden_dim = 64\n",
    "        self.lambd = 1\n",
    "        self.lambd_geo = 100\n",
    "        self.lambd_arap = 1\n",
    "\n",
    "        self.log_freq = 1\n",
    "        self.val_freq = 1\n",
    "\n",
    "        self.log = True\n",
    "\n",
    "def create_correspondence_model(dataset, dataset_val=None, time_stamp=None, description=\"\", param=NetworkParameters(), folder_weights_load=None):\n",
    "    if time_stamp is None:\n",
    "        time_stamp = get_timestr()\n",
    "\n",
    "    # Deformation model based on the \"As-rigid-as-possible\" energy formulation (Olga Sorkine and Marc Alexa, 2007)\n",
    "    interpol_energy = ArapInterpolationEnergy()\n",
    "\n",
    "    # Correspondence model\n",
    "    interpol_module = InterpolationModGeoEC(interpol_energy, param).to(device)\n",
    "\n",
    "    \n",
    "    preproc_mods = []\n",
    "    preproc_mods.append(PreprocessRotateSame(dataset.axis))\n",
    "    \n",
    "    settings_module = timestep_settings(increase_thresh=3)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(dataset, shuffle=True)\n",
    "    if dataset_val is not None:\n",
    "        val_loader = torch.utils.data.DataLoader(dataset_val, shuffle=False)\n",
    "    else:\n",
    "        val_loader = None\n",
    "\n",
    "    interpol = InterpolNet(interpol_module, train_loader, val_loader=val_loader, time_stamp=time_stamp, description=description, preproc_mods=preproc_mods, settings_module=settings_module)\n",
    "\n",
    "    if folder_weights_load is not None:\n",
    "        interpol.load_self(save_path(folder_str=folder_weights_load))\n",
    "\n",
    "    return interpol\n",
    "\n",
    "data_folder = \"./data/\"\n",
    "\n",
    "# # determine which meshes to use\n",
    "# all_fnames = getFiles(join(data_folder, \"meshes\"))\n",
    "# train_inds, val_inds, _ = k_fold_split_train_val_test(dataset_size=len(all_fnames), fold_num=1, seed=1004)\n",
    "# train_fnames = [all_fnames[i].replace('.obj','') for i in train_inds]\n",
    "# val_fnames = [all_fnames[i].replace('.obj','') for i in val_inds]\n",
    "\n",
    "train_fnames = [\"bear\", \"camel\", \"dog\", \"elephant\", \"giraffe\", \"hippo\", \"leopard\", \"pig\", \"rhino\"] \n",
    "#val_fnames = [\"bison\", \"cow\"]\n",
    "\n",
    "dataset_train = general_dataset(data_folder, fnames=train_fnames, load_dist_mat=True)\n",
    "#dataset_val = general_dataset(data_folder, fnames=val_fnames, load_dist_mat=True)\n",
    "\n",
    "correspondence_model = create_correspondence_model(dataset_train, dataset_val=None, description=f\"test1\")\n",
    "correspondence_model.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retry inference with a model that has been trained for a single epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model and some mesh data\n",
    "data_folder = \"data/meshes\"\n",
    "source_mesh = o3d.io.read_triangle_mesh(join(data_folder, \"bison.obj\"))\n",
    "target_mesh = o3d.io.read_triangle_mesh(join(data_folder, \"cow.obj\"))\n",
    "\n",
    "# inference\n",
    "result = run_correpondence_inference(correspondence_model.interp_module, source_mesh, target_mesh)\n",
    "\n",
    "# display outputs (visualise)\n",
    "source_verts = result[\"X\"][\"verts\"][:, [0,2,1]] # just reordering x, y, z for visualisation\n",
    "target_verts = result[\"Y\"][\"verts\"][:, [0,2,1]] # just reordering x, y, z for visualisation\n",
    "triangles_x = result[\"X\"][\"triangles\"]\n",
    "triangles_y = result[\"Y\"][\"triangles\"]\n",
    "\n",
    "# offset\n",
    "target_verts = target_verts + np.array([1,0,0])\n",
    "\n",
    "pyvista.global_theme.background = 'white'\n",
    "plotter = pyvista.Plotter(notebook=True)\n",
    "\n",
    "# Forward assignment\n",
    "# set colours on target mesh corresponding with xyz position\n",
    "target_colours = target_verts - np.min(target_verts, axis=0)\n",
    "target_colours = target_colours / np.max(target_colours, axis=0)\n",
    "target_colours = np.concatenate([target_colours, np.ones((len(target_colours), 1))], axis=1)\n",
    "# set colours on source mesh according to the predicted correspondence assignment\n",
    "assignment = result[\"assignment\"]\n",
    "source_colours = target_colours[assignment]\n",
    "\n",
    "# add points\n",
    "plotter.add_points(target_verts, opacity=1., point_size=10, render_points_as_spheres=True, scalars=target_colours, rgb=True)\n",
    "plotter.add_points(source_verts, opacity=1., point_size=10, render_points_as_spheres=True, scalars=source_colours, rgb=True)\n",
    "plotter.show(jupyter_backend=\"static\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model trained for many epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "from neuromorph_adapted.model.interpolation_net import *\n",
    "from neuromorph_adapted.utils.arap import ArapInterpolationEnergy\n",
    "from neuromorph_adapted.data.data import *\n",
    "from neuromorph_adapted.utils.utils import ParametersBase\n",
    "import pyvista\n",
    "\n",
    "class NetworkParameters(ParametersBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lr = 1e-4\n",
    "        self.num_it = 1\n",
    "        self.batch_size = 16\n",
    "        self.num_timesteps = 0\n",
    "        self.hidden_dim = 128\n",
    "        self.lambd = 1\n",
    "        self.lambd_geo = 100\n",
    "        self.lambd_arap = 1\n",
    "\n",
    "        self.log_freq = 1\n",
    "        self.val_freq = 1\n",
    "\n",
    "        self.log = True\n",
    "\n",
    "interpol_energy = ArapInterpolationEnergy()\n",
    "correspondence_model = InterpolationModGeoEC(interpol_energy, param=NetworkParameters()).to(device)\n",
    "correspondence_model.load_self(\"./\", num_epoch=229)\n",
    "\n",
    "# load the model and some mesh data\n",
    "data_folder = \"data/meshes\"\n",
    "source_mesh = o3d.io.read_triangle_mesh(join(data_folder, \"bison.obj\"))\n",
    "target_mesh = o3d.io.read_triangle_mesh(join(data_folder, \"cow.obj\"))\n",
    "\n",
    "# inference\n",
    "result = run_correpondence_inference(correspondence_model, source_mesh, target_mesh)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(\"results/trained_correspondence_result.pkl\", \"wb\") as f:\n",
    "    pickle.dump(result, f)\n",
    "\n",
    "# display outputs (visualise)\n",
    "source_verts = result[\"X\"][\"verts\"][:, [0,2,1]] # just reordering x, y, z for visualisation\n",
    "target_verts = result[\"Y\"][\"verts\"][:, [0,2,1]] # just reordering x, y, z for visualisation\n",
    "triangles_x = result[\"X\"][\"triangles\"]\n",
    "triangles_y = result[\"Y\"][\"triangles\"]\n",
    "\n",
    "# offset\n",
    "target_verts = target_verts + np.array([1,0,0])\n",
    "\n",
    "pyvista.global_theme.background = 'white'\n",
    "plotter = pyvista.Plotter(notebook=True)\n",
    "\n",
    "# Forward assignment\n",
    "# set colours on target mesh corresponding with xyz position\n",
    "target_colours = target_verts - np.min(target_verts, axis=0)\n",
    "target_colours = target_colours / np.max(target_colours, axis=0)\n",
    "target_colours = np.concatenate([target_colours, np.ones((len(target_colours), 1))], axis=1)\n",
    "# set colours on source mesh according to the predicted correspondence assignment\n",
    "assignment = result[\"assignment\"]\n",
    "source_colours = target_colours[assignment]\n",
    "\n",
    "# add points\n",
    "plotter.add_points(target_verts, opacity=1., point_size=10, render_points_as_spheres=True, scalars=target_colours, rgb=True)\n",
    "plotter.add_points(source_verts, opacity=1., point_size=10, render_points_as_spheres=True, scalars=source_colours, rgb=True)\n",
    "plotter.show(jupyter_backend=\"static\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical evaluation\n",
    "Need to create some evaluation steps and metrics\n",
    "## we're going to use these landmarks and the geodesic dsistances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "# display outputs (visualise)\n",
    "source_verts = result[\"X\"][\"verts\"][:, [0,2,1]] # just reordering x, y, z for visualisation\n",
    "target_verts = result[\"Y\"][\"verts\"][:, [0,2,1]] # just reordering x, y, z for visualisation\n",
    "triangles_x = result[\"X\"][\"triangles\"]\n",
    "triangles_y = result[\"Y\"][\"triangles\"]\n",
    "\n",
    "# offset\n",
    "target_verts = target_verts + np.array([1,0,0])\n",
    "\n",
    "pyvista.global_theme.background = 'white'\n",
    "plotter = pyvista.Plotter(notebook=True)\n",
    "\n",
    "# Forward assignment\n",
    "# set colours on target mesh corresponding with xyz position\n",
    "target_colours = target_verts - np.min(target_verts, axis=0)\n",
    "target_colours = target_colours / np.max(target_colours, axis=0)\n",
    "target_colours = np.concatenate([target_colours, np.ones((len(target_colours), 1))], axis=1)\n",
    "# set colours on source mesh according to the predicted correspondence assignment\n",
    "assignment = result[\"assignment\"]\n",
    "source_colours = target_colours[assignment]\n",
    "\n",
    "# add points\n",
    "plotter.add_points(target_verts, opacity=1., point_size=10, render_points_as_spheres=True, scalars=target_colours, rgb=True)\n",
    "plotter.add_points(source_verts, opacity=1., point_size=10, render_points_as_spheres=True, scalars=source_colours, rgb=True)\n",
    "\n",
    "\n",
    "\n",
    "bison_landmark_indices = sio.loadmat(\"data/ground_truth_landmarks/bison.mat\")\n",
    "cow_landmark_indices = sio.loadmat(\"data/ground_truth_landmarks/cow.mat\")\n",
    "source_landmark_indices = {k: v for k, v in zip(list(bison_landmark_indices[\"points\"].flatten()), list(bison_landmark_indices[\"centroids\"]))}\n",
    "target_landmark_indices = {k: v for k, v in zip(list(cow_landmark_indices[\"points\"].flatten()), list(cow_landmark_indices[\"centroids\"]))}\n",
    "correspondence_lookup = {k: v for k, v in enumerate(assignment)}\n",
    "common_landmarks = list(set(source_landmark_indices.keys()) & set(target_landmark_indices.keys()))\n",
    "\n",
    "s_l = (np.array(list(source_landmark_indices.values())) - result[\"X\"][\"shift\"].numpy())[:, [0,2,1]]\n",
    "t_l = (np.array(list(target_landmark_indices.values())) - result[\"Y\"][\"shift\"].numpy())[:, [0,2,1]] + np.array([1,0,0])\n",
    "plotter.add_points(s_l, opacity=1., point_size=20, render_points_as_spheres=True, color='r')\n",
    "plotter.add_points(t_l, opacity=1., point_size=20, render_points_as_spheres=True, color='r')\n",
    "\n",
    "plotter.show(jupyter_backend=\"static\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "from scipy.spatial import KDTree\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "\n",
    "# evaluate before and after training\n",
    "# Geodesic distance normalised by the square root area of the mesh\n",
    "def get_geodesic_error(geodesic_dists_x, geodesic_dists_y, assignment, area_y, n_sample=10000):\n",
    "    geodesic_dists_x_prime = geodesic_dists_y[assignment]\n",
    "    geodesic_dists_x_prime = geodesic_dists_x_prime[:, assignment]\n",
    "    error = np.abs(geodesic_dists_x - geodesic_dists_x_prime)\n",
    "\n",
    "    # errors normalised by the square root area of the mesh\n",
    "    geodesic_error = (1 / np.sqrt(area_y)) * error\n",
    "    # sample n_sample points\n",
    "    geodesic_error = geodesic_error.reshape(-1)\n",
    "    geodesic_error_sample = np.random.choice(geodesic_error, n_sample, replace=False)\n",
    "    return geodesic_error_sample\n",
    "\n",
    "\n",
    "# landmark based error\n",
    "def get_nearest_vertices_to_landmarks(landmarks, vertices):\n",
    "    kdtree = KDTree(vertices)\n",
    "    nearest_vertices = {}\n",
    "    for landmark_index, landmark in landmarks.items():\n",
    "        nearest_vertices[landmark_index] = kdtree.query(landmark)[1]\n",
    "    return nearest_vertices\n",
    "\n",
    "def landmark_errors(source_landmark_vertices, target_landmark_vertices, assignment, target_geodesic_dists, target_area):\n",
    "    correspondence_lookup = {k: v for k, v in enumerate(assignment)}\n",
    "    common_landmark_indices = list(set(source_landmark_vertices.keys()) & set(target_landmark_vertices.keys()))\n",
    "    errors = []\n",
    "    for landmark_index in common_landmark_indices:\n",
    "        source_landmark = source_landmark_vertices[landmark_index]\n",
    "        target_landmark = target_landmark_vertices[landmark_index]\n",
    "        target_landmark_prime = correspondence_lookup[source_landmark]\n",
    "        error = target_geodesic_dists[target_landmark, target_landmark_prime] / np.sqrt(target_area)\n",
    "        errors.append(error)\n",
    "    return errors\n",
    "\n",
    "# load evaluation datasets\n",
    "bison_landmarks = sio.loadmat(\"data/ground_truth_landmarks/bison.mat\")\n",
    "cow_landmarks = sio.loadmat(\"data/ground_truth_landmarks/cow.mat\")\n",
    "bison_vertices = np.asarray(o3d.io.read_triangle_mesh(join(data_folder, \"bison.obj\")).vertices)\n",
    "cow_vertices = np.asarray(o3d.io.read_triangle_mesh(join(data_folder, \"cow.obj\")).vertices)\n",
    "cow_geodesic_dists = np.load(\"data/geodesic_distances/cow.npy\")\n",
    "bison_geodesic_dists = np.load(\"data/geodesic_distances/bison.npy\")\n",
    "cow_area = target_mesh.get_surface_area()\n",
    "\n",
    "bison_landmarks = {k: v for k, v in zip(list(bison_landmarks[\"points\"].flatten()), list(bison_landmarks[\"centroids\"]))}\n",
    "cow_landmarks = {k: v for k, v in zip(list(cow_landmarks[\"points\"].flatten()), list(cow_landmarks[\"centroids\"]))}\n",
    "bison_landmark_vertices = get_nearest_vertices_to_landmarks(bison_landmarks, bison_vertices)\n",
    "cow_landmark_vertices = get_nearest_vertices_to_landmarks(cow_landmarks, cow_vertices)\n",
    "\n",
    "# load the resulting correspondences from the randomly initialised model\n",
    "with open(\"results/random_init_correspondence_result.pkl\", \"rb\") as f:\n",
    "    result = pickle.load(f)\n",
    "# compute the errors\n",
    "random_init_errors = landmark_errors(bison_landmark_vertices, cow_landmark_vertices, result[\"assignment\"], cow_geodesic_dists, cow_area)\n",
    "random_init_geodesic_error = get_geodesic_error(bison_geodesic_dists, cow_geodesic_dists, result[\"assignment\"], cow_area)\n",
    "\n",
    "# load the resulting correspondences from the trained model\n",
    "with open(\"results/trained_correspondence_result.pkl\", \"rb\") as f:\n",
    "    result = pickle.load(f)\n",
    "# compute the errors\n",
    "trained_errors = landmark_errors(bison_landmark_vertices, cow_landmark_vertices, result[\"assignment\"], cow_geodesic_dists, cow_area)\n",
    "trained_geodesic_error = get_geodesic_error(bison_geodesic_dists, cow_geodesic_dists, result[\"assignment\"], cow_area)\n",
    "\n",
    "# for fun - generate error metrics from randomly assigned correspondences\n",
    "random_assignment = np.random.choice(len(cow_vertices), size=len(bison_vertices))\n",
    "no_model_errors = landmark_errors(bison_landmark_vertices, cow_landmark_vertices, random_assignment, cow_geodesic_dists, cow_area)\n",
    "no_model_geodesic_error = get_geodesic_error(bison_geodesic_dists, cow_geodesic_dists, random_assignment, cow_area)\n",
    "\n",
    "## Quick plotting of the errors\n",
    "fig, (ax0,ax1) = plt.subplots(1,2, figsize=(14,6))\n",
    "\n",
    "# violin plots for the ground truth landmark errors\n",
    "violinplots = ax0.violinplot([no_model_errors, random_init_errors, trained_errors], positions=[1, 1.6, 2.2], showmeans=True,)\n",
    "ax0.set_xticks([1, 1.6, 2.2])\n",
    "ax0.set_xticklabels([\"No model\", \"Random\\ninitialisation\", \"Trained model\"])\n",
    "ax0.set_ylabel(\"Normalised landmark error\")\n",
    "ax0.set_ylim(0)\n",
    "colours = ['red', 'blue', 'green']\n",
    "for i, plot_body in enumerate(violinplots['bodies']):\n",
    "    plot_body.set_facecolor(colours[i])\n",
    "    plot_body.set_edgecolor('black')\n",
    "    plot_body.set_alpha(1)\n",
    "for line in ['cbars','cmins','cmaxes']:\n",
    "    violinplots[line].set_color('black')\n",
    "    violinplots[line].set_linewidth(2)\n",
    "violinplots['cmeans'].set_linestyle('--')\n",
    "violinplots['cmeans'].set_color('white')\n",
    "violinplots['cmeans'].set_linewidth(2)\n",
    "\n",
    "# cumulative distribution of the geodesic errors\n",
    "ax1.plot(np.sort(no_model_geodesic_error), np.linspace(0, 100, len(no_model_geodesic_error)), c=colours[0], label=\"No model\")\n",
    "ax1.plot(np.sort(random_init_geodesic_error), np.linspace(0, 100, len(random_init_geodesic_error)), c=colours[1], label=\"Random init\")\n",
    "ax1.plot(np.sort(trained_geodesic_error), np.linspace(0, 100, len(trained_geodesic_error)), c=colours[2], label=\"Trained\")\n",
    "\n",
    "ax1.set_xlabel(\"Geodesic error\")\n",
    "ax1.set_ylabel(r\"% of matches\")\n",
    "ax1.set_ylim(0, 100)\n",
    "ax1.set_xlim(0)\n",
    "ax1.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about training on a large separate dataset - not possible in time, show pictures of the faust dataset and explain how could be extended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does this work pretty well on an un-trained network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application to radiotherapy - show pictures from lecture on how this model was extended to organ shapes and use of imaging"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eds_dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
